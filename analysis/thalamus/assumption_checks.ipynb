{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a71ae6e",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0fa131",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2acf5a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "import re\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import helpers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from matplotlib import colormaps\n",
    "from scipy import stats\n",
    "from statsmodels.regression import linear_model\n",
    "\n",
    "# from reload_recursive import reload_recursive\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from mri_data import file_manager as fm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579ab1df",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f89159",
   "metadata": {},
   "source": [
    "#### Clinical and Volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df985042",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_root = fm.get_drive_root()\n",
    "dataroot = drive_root / \"3Tpioneer_bids\"\n",
    "data_dir = Path(\"/home/srs-9/Projects/ms_mri/data\")\n",
    "fig_path = Path(\n",
    "    \"/home/srs-9/Projects/ms_mri/analysis/thalamus/figures_tables/assumption_checks\"\n",
    ")\n",
    "\n",
    "choroid_volumes = pd.read_csv(\n",
    "    \"/home/srs-9/Projects/ms_mri/data/choroid_aschoplex_volumes.csv\", index_col=\"subid\"\n",
    ")\n",
    "ventricle_volumes = pd.read_csv(\n",
    "    \"/home/srs-9/Projects/ms_mri/analysis/paper1/data0/ventricle_volumes.csv\",\n",
    "    index_col=\"subid\",\n",
    ")\n",
    "csf_volumes = pd.read_csv(\n",
    "    \"/home/srs-9/Projects/ms_mri/analysis/thalamus/data0/csf_volumes2.csv\",\n",
    "    index_col=\"subid\",\n",
    ")\n",
    "third_ventricle_width = pd.read_csv(\n",
    "    \"/home/srs-9/Projects/ms_mri/analysis/thalamus/data0/third_ventricle_width.csv\",\n",
    "    index_col=\"subid\",\n",
    ")\n",
    "\n",
    "tiv = pd.read_csv(\"/home/srs-9/Projects/ms_mri/data/tiv_data.csv\", index_col=\"subid\")\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"/home/srs-9/Projects/ms_mri/data/clinical_data_processed.csv\", index_col=\"subid\"\n",
    ")\n",
    "sdmt = pd.read_csv(\n",
    "    \"/home/srs-9/Projects/ms_mri/analysis/thalamus/SDMT_sheet.csv\", index_col=\"subid\"\n",
    ")\n",
    "df = df.join(\n",
    "    [\n",
    "        choroid_volumes,\n",
    "        ventricle_volumes,\n",
    "        csf_volumes,\n",
    "        third_ventricle_width,\n",
    "        tiv,\n",
    "        sdmt[\"SDMT\"],\n",
    "    ]\n",
    ")\n",
    "rename_columns = {\n",
    "    \"ventricle_volume\": \"LV\",\n",
    "    \"choroid_volume\": \"CP\",\n",
    "    \"peripheral\": \"periCSF\",\n",
    "    \"all\": \"allCSF\",\n",
    "    \"third_ventricle\": \"thirdV\",\n",
    "    \"third_ventricle_width\": \"thirdV_width\"\n",
    "}\n",
    "#! need to fix the actual segmentation files\n",
    "df.rename(columns=rename_columns, inplace=True)\n",
    "\n",
    "df[\"periCSF_frac\"] = csf_volumes[\"peripheral\"] / csf_volumes[\"all\"]\n",
    "\n",
    "df[\"SDMT\"] = pd.to_numeric(df[\"SDMT\"], errors=\"coerce\")\n",
    "df[\"thalamus_sqrt\"] = np.sqrt(df[\"thalamus\"])\n",
    "df[\"thalamus_curt\"] = np.sqrt(df[\"thalamus\"] ** 3)\n",
    "df[\"cortical_thickness_inv\"] = 1 / df[\"cortical_thickness\"]\n",
    "df[\"LV_logtrans\"] = np.log(df[\"LV\"])\n",
    "\n",
    "# these corrections should ultimately be made to the csf file\n",
    "for struct in [\"brain\", \"white\", \"grey\", \"thalamus\", \"t2lv\"]:\n",
    "    df[struct] = df[struct] * 1000\n",
    "\n",
    "df[\"CCF\"] = df[\"LV\"] / df[\"allCSF\"]\n",
    "df[\"peri_ratio\"] = df[\"periCSF\"] / df[\"LV\"]\n",
    "\n",
    "\n",
    "df_z = df.copy()\n",
    "numeric_cols = df.select_dtypes(include=\"number\").columns\n",
    "df_z[numeric_cols] = df_z[numeric_cols].apply(stats.zscore, nan_policy=\"omit\")\n",
    "\n",
    "viridis = colormaps[\"viridis\"].resampled(20)\n",
    "\n",
    "colors = helpers.get_colors()\n",
    "\n",
    "MS_patients = df[\"dz_type2\"] == \"MS\"\n",
    "nonMS_patients = df[\"dz_type2\"] == \"!MS\"\n",
    "NIND_patients = df[\"dz_type5\"] == \"NIND\"\n",
    "OIND_patients = df[\"dz_type5\"] == \"OIND\"\n",
    "RMS_patients = df[\"dz_type5\"] == \"RMS\"\n",
    "PMS_patients = df[\"dz_type5\"] == \"PMS\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7611cfb",
   "metadata": {},
   "source": [
    "#### HIPS-THOMAS Volumes and Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87bf224b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thomas = pd.read_csv(data_dir / \"hipsthomas_vols.csv\", index_col=\"subid\")\n",
    "df_thomas_left = pd.read_csv(data_dir / \"hipsthomas_left_vols.csv\", index_col=\"subid\")\n",
    "df_thomas_right = pd.read_csv(data_dir / \"hipsthomas_right_vols.csv\", index_col=\"subid\")\n",
    "\n",
    "cols_orig = df_thomas.columns\n",
    "new_colnames = {}\n",
    "for col in df_thomas.columns:\n",
    "    new_col = re.sub(r\"(\\d+)-([\\w-]+)\", r\"\\2_\\1\", col)\n",
    "    new_col = re.sub(\"-\", \"_\", new_col)\n",
    "    new_colnames[col] = new_col\n",
    "\n",
    "df_thomas = df_thomas.rename(columns=new_colnames)\n",
    "df_thomas_left = df_thomas_left.rename(columns=new_colnames)\n",
    "df_thomas_right = df_thomas_right.rename(columns=new_colnames)\n",
    "\n",
    "nuclei_groupings = {\n",
    "    \"anterior\": [\"AV_2\"],\n",
    "    \"ventral\": [\"VA_4\", \"VLa_5\", \"VLP_6\", \"VPL_7\"],\n",
    "    \"posterior\": [\"Pul_8\", \"LGN_9\", \"MGN_10\"],\n",
    "    \"medial\": [\"MD_Pf_12\", \"CM_11\"],\n",
    "}\n",
    "\n",
    "\n",
    "def combine_nuclei(df, groupings):\n",
    "    df2 = pd.DataFrame()\n",
    "    for group, nuclei in groupings.items():\n",
    "        df2[group] = sum([df[nucleus] for nucleus in nuclei])\n",
    "    return df2\n",
    "\n",
    "\n",
    "df_thomas = df_thomas.join(combine_nuclei(df_thomas, nuclei_groupings))\n",
    "df_thomas_left = df_thomas_left.join(combine_nuclei(df_thomas_left, nuclei_groupings))\n",
    "df_thomas_right = df_thomas_right.join(\n",
    "    combine_nuclei(df_thomas_right, nuclei_groupings)\n",
    ")\n",
    "\n",
    "\n",
    "thalamic_nuclei = [2, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "thalamic_nuclei_str = [str(i) for i in thalamic_nuclei]\n",
    "deep_grey = [13, 14, 26, 27, 28, 29, 30, 31, 32]\n",
    "deep_grey_str = [str(i) for i in deep_grey]\n",
    "\n",
    "\n",
    "hips_thomas_ref = pd.read_csv(\n",
    "    \"/home/srs-9/Projects/ms_mri/data/hipsthomas_struct_index.csv\", index_col=\"index\"\n",
    ")[\"struct\"]\n",
    "hips_thomas_invref = pd.read_csv(\n",
    "    \"/home/srs-9/Projects/ms_mri/data/hipsthomas_struct_index.csv\", index_col=\"struct\"\n",
    ")[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5def8a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore(df):\n",
    "    df_z = df.copy()\n",
    "    numeric_cols = df.select_dtypes(include=\"number\").columns\n",
    "    df_z[numeric_cols] = df_z[numeric_cols].apply(stats.zscore, nan_policy=\"omit\")\n",
    "    return df_z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d538068d",
   "metadata": {},
   "source": [
    "### **Phase 1: Individual Variable Screening (Before Modeling)**\n",
    "\n",
    "For each continuous variable (predictors AND outcome):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e3baf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def screen_variable(data, var_name, show=False, save=False, save_dir=None):\n",
    "    if save_dir is None:\n",
    "        save_dir = fig_path\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "    # Histogram\n",
    "    axes[0, 0].hist(data[var_name].dropna(), bins=30, edgecolor='black')\n",
    "    axes[0, 0].set_title(f'Histogram: {var_name}')\n",
    "    axes[0, 0].set_xlabel(var_name)\n",
    "\n",
    "    # Q-Q plot\n",
    "    stats.probplot(data[var_name].dropna(), dist=\"norm\", plot=axes[0, 1])\n",
    "    axes[0, 1].set_title(f'Q-Q Plot: {var_name}')\n",
    "\n",
    "    # Boxplot\n",
    "    axes[1, 0].boxplot(data[var_name].dropna())\n",
    "    axes[1, 0].set_title(f'Boxplot: {var_name}')\n",
    "    axes[1, 0].set_ylabel(var_name)\n",
    "\n",
    "    # Summary stats\n",
    "    axes[1, 1].axis('off')\n",
    "    summary = data[var_name].describe()\n",
    "    skew = data[var_name].skew()\n",
    "    kurt = data[var_name].kurtosis()\n",
    "\n",
    "    summary_text = f\"\"\"\n",
    "    Mean: {summary['mean']:.2f}\n",
    "    Median: {summary['50%']:.2f}\n",
    "    Std: {summary['std']:.2f}\n",
    "    Min: {summary['min']:.2f}\n",
    "    Max: {summary['max']:.2f}\n",
    "    \n",
    "    Skewness: {skew:.2f}\n",
    "    Kurtosis: {kurt:.2f}\n",
    "    \n",
    "    Rule of thumb:\n",
    "    |Skew| < 1: OK\n",
    "    |Skew| 1-2: Moderate\n",
    "    |Skew| > 2: Severe\n",
    "    \"\"\"\n",
    "    axes[1, 1].text(0.1, 0.5, summary_text, fontsize=10, family='monospace')\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig(\n",
    "            f'{save_dir}/{var_name}_screening.png', dpi=300, bbox_inches='tight'\n",
    "        )\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "\n",
    "    return skew, kurt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19071eae",
   "metadata": {},
   "source": [
    "#### **3. Choose Appropriate Transformation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3476739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_transformation(data, var_name):\n",
    "    \"\"\"\n",
    "    Suggests transformation based on distribution characteristics\n",
    "    \"\"\"\n",
    "    skew = data[var_name].skew()\n",
    "    has_zeros = (data[var_name] == 0).any()\n",
    "    has_negatives = (data[var_name] < 0).any()\n",
    "    \n",
    "    print(f\"\\n{var_name} Transformation Recommendations:\")\n",
    "    print(f\"Skewness: {skew:.2f}\")\n",
    "    \n",
    "    if abs(skew) < 1:\n",
    "        print(\"→ No transformation needed\")\n",
    "        return False\n",
    "    \n",
    "    if skew > 1:  # Right skewed\n",
    "        print(\"→ Right-skewed distribution detected\")\n",
    "        if has_negatives:\n",
    "            print(\"  ⚠ Has negative values - consider:\")\n",
    "            print(\"    - Box-Cox (after shifting)\")\n",
    "            print(\"    - Yeo-Johnson\")\n",
    "        elif has_zeros:\n",
    "            print(\"  ⚠ Has zeros - consider:\")\n",
    "            print(\"    - log(x + 1)\")\n",
    "            print(\"    - sqrt(x)\")\n",
    "        else:\n",
    "            print(\"  Recommended: log(x)\")\n",
    "            print(\"  Alternative: sqrt(x)\")\n",
    "    \n",
    "    elif skew < -1:  # Left skewed\n",
    "        print(\"→ Left-skewed distribution detected\")\n",
    "        print(\"  Recommended: square (x²) or reflect + log\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def suggest_transformation(data, var_name):\n",
    "    \"\"\"\n",
    "    Suggests transformation based on distribution characteristics\n",
    "    \"\"\"\n",
    "    skew = data[var_name].skew()\n",
    "    has_zeros = (data[var_name] == 0).any()\n",
    "    has_negatives = (data[var_name] < 0).any()\n",
    "    \n",
    "    print(f\"\\n{var_name} Transformation Recommendations:\")\n",
    "    print(f\"Skewness: {skew:.2f}\")\n",
    "    \n",
    "    if abs(skew) < 1:\n",
    "        print(\"→ No transformation needed\")\n",
    "        return None\n",
    "    \n",
    "    if skew > 1:  # Right skewed\n",
    "        print(\"→ Right-skewed distribution detected\")\n",
    "        if has_negatives:\n",
    "            print(\"  ⚠ Has negative values - consider:\")\n",
    "            print(\"    - Box-Cox (after shifting)\")\n",
    "            print(\"    - Yeo-Johnson\")\n",
    "        elif has_zeros:\n",
    "            print(\"  ⚠ Has zeros - consider:\")\n",
    "            print(\"    - log(x + 1)\")\n",
    "            print(\"    - sqrt(x)\")\n",
    "        else:\n",
    "            print(\"  Recommended: log(x)\")\n",
    "            print(\"  Alternative: sqrt(x)\")\n",
    "    \n",
    "    elif skew < -1:  # Left skewed\n",
    "        print(\"→ Left-skewed distribution detected\")\n",
    "        print(\"  Recommended: square (x²) or reflect + log\")\n",
    "    \n",
    "    return skew\n",
    "\n",
    "#! will figure something out for boxcox and yeojohnson later if necessary: they both return a 2-tuple\n",
    "transforms = {\n",
    "    \"log\": np.log,\n",
    "    \"log10\": np.log10,\n",
    "    \"logp1\": np.log1p,\n",
    "    \"sqrt\": np.sqrt,\n",
    "    \"boxcox\": stats.boxcox,\n",
    "    \"yeojohnson\": stats.yeojohnson\n",
    "}\n",
    "\n",
    "def apply_transformations(data, var_name, transformations=None):\n",
    "    \"\"\"\n",
    "    Creates multiple transformations for comparison\n",
    "    \"\"\"\n",
    "    if transformations is None:\n",
    "        transformations = [\"log\", \"log10\", \"logp1\", \"sqrt\", \"boxcox\", \"yeojohnson\"]\n",
    "        \n",
    "    transformed = {}\n",
    "    \n",
    "    # Original\n",
    "    transformed['original'] = data[var_name].copy()\n",
    "\n",
    "    for transform_name in transformations:\n",
    "        transform_func = transforms[transform_name]\n",
    "        transformed[transform_name] = transform_func(data[var_name])\n",
    "\n",
    "    return transformed\n",
    "\n",
    "\n",
    "def transform_data(data, var_name, transformations=None):\n",
    "    transformed = apply_transformations(data, var_name, transformations=transformations)\n",
    "    new_data = data.copy()\n",
    "    for transform in transformed:\n",
    "        new_data[f\"{var_name}_{transform}\"] = transformed[transform]\n",
    "\n",
    "    return new_data\n",
    "\n",
    "\n",
    "def apply_transformations0(data, var_name, transformations=None):\n",
    "    \"\"\"\n",
    "    Creates multiple transformations for comparison\n",
    "    \"\"\"\n",
    "    transformed = {}\n",
    "    \n",
    "    # Original\n",
    "    transformed['original'] = data[var_name].copy()\n",
    "    \n",
    "    # Log (if no zeros/negatives)\n",
    "    if (data[var_name] > 0).all():\n",
    "        transformed['log'] = np.log(data[var_name])\n",
    "        transformed['log10'] = np.log10(data[var_name])\n",
    "    \n",
    "    # Log(x+1) - works with zeros\n",
    "    if (data[var_name] >= 0).all():\n",
    "        transformed['log1p'] = np.log1p(data[var_name])\n",
    "    \n",
    "    # Square root - works with zeros\n",
    "    if (data[var_name] >= 0).all():\n",
    "        transformed['sqrt'] = np.sqrt(data[var_name])\n",
    "    \n",
    "    # Box-Cox (requires positive values)\n",
    "    if (data[var_name] > 0).all():\n",
    "        transformed, lambda_param = stats.boxcox(data[var_name])\n",
    "        transformed[f'boxcox(λ={lambda_param:.2f})'] = transformed\n",
    "    \n",
    "    # Yeo-Johnson (works with any values)\n",
    "    transformed, lambda_param = stats.yeojohnson(data[var_name])\n",
    "    transformed[f'yeojohnson(λ={lambda_param:.2f})'] = transformed\n",
    "    \n",
    "    return transformed\n",
    "\n",
    "def compare_transformations(data, var_name):\n",
    "    \"\"\"\n",
    "    Compares all possible transformations\n",
    "    \"\"\"\n",
    "    trans = apply_transformations(data, var_name)\n",
    "    \n",
    "    results = []\n",
    "    for trans_name, trans_data in trans.items():\n",
    "        skew = trans_data.skew()\n",
    "        kurt = trans_data.kurtosis()\n",
    "        results.append({\n",
    "            'transformation': trans_name,\n",
    "            'skewness': skew,\n",
    "            'kurtosis': kurt,\n",
    "            'abs_skew': abs(skew)\n",
    "        })\n",
    "    \n",
    "    import pandas as pd\n",
    "    df_results = pd.DataFrame(results).sort_values('abs_skew')\n",
    "    \n",
    "    print(f\"\\n{var_name} - Transformation Comparison:\")\n",
    "    print(df_results.to_string(index=False))\n",
    "    \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b002506b",
   "metadata": {},
   "source": [
    "**2. Decision Rules for Transformation**\n",
    "\n",
    "| Criterion | Action |\n",
    "|-----------|--------|\n",
    "| \\|Skewness\\| > 2 | Strongly consider transformation |\n",
    "| \\|Skewness\\| 1-2 | Consider transformation, check residuals first |\n",
    "| \\|Skewness\\| < 1 | Probably fine, but still check residuals |\n",
    "| Heavy outliers (>3 SD) | Investigate; may need robust methods or transformation |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa57ab0",
   "metadata": {},
   "source": [
    "### **Phase 2: Post-Modeling Diagnostics (After Fitting)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c0b64c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_diagnostics(model, data, save_dir=None):\n",
    "    \"\"\"\n",
    "    Complete diagnostic check suite\n",
    "    \"\"\"\n",
    "    from statsmodels.graphics.gofplots import ProbPlot\n",
    "    if save_dir is None:\n",
    "        save_dir = fig_path\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    X = data[model.model.exog_names[1:]]\n",
    "    X['cont'] = 1\n",
    "    # Get residuals and fitted values\n",
    "    residuals = model.resid\n",
    "    fitted = model.fittedvalues\n",
    "    standardized_resid = (residuals - residuals.mean()) / residuals.std()\n",
    "    \n",
    "    # Studentized residuals\n",
    "    from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "    influence = OLSInfluence(model)\n",
    "    studentized_resid = influence.resid_studentized_internal\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "    \n",
    "    # 1. Residuals vs Fitted (Linearity & Homoscedasticity)\n",
    "    axes[0, 0].scatter(fitted, residuals, alpha=0.5)\n",
    "    axes[0, 0].axhline(y=0, color='r', linestyle='--')\n",
    "    axes[0, 0].set_xlabel('Fitted values')\n",
    "    axes[0, 0].set_ylabel('Residuals')\n",
    "    axes[0, 0].set_title('Residuals vs Fitted\\n(Check: linearity, homoscedasticity)')\n",
    "    \n",
    "    # Add lowess line\n",
    "    from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "    lowess_line = lowess(residuals, fitted, frac=0.3)\n",
    "    axes[0, 0].plot(lowess_line[:, 0], lowess_line[:, 1], 'g-', linewidth=2)\n",
    "    \n",
    "    # 2. Q-Q plot (Normality of residuals)\n",
    "    ProbPlot(standardized_resid).qqplot(line='45', ax=axes[0, 1])\n",
    "    axes[0, 1].set_title('Q-Q Plot\\n(Check: normality of residuals)')\n",
    "    \n",
    "    # 3. Scale-Location (Homoscedasticity)\n",
    "    axes[0, 2].scatter(fitted, np.sqrt(np.abs(standardized_resid)), alpha=0.5)\n",
    "    axes[0, 2].set_xlabel('Fitted values')\n",
    "    axes[0, 2].set_ylabel('√|Standardized residuals|')\n",
    "    axes[0, 2].set_title('Scale-Location\\n(Check: homoscedasticity)')\n",
    "    lowess_line = lowess(np.sqrt(np.abs(standardized_resid)), fitted, frac=0.3)\n",
    "    axes[0, 2].plot(lowess_line[:, 0], lowess_line[:, 1], 'r-', linewidth=2)\n",
    "    \n",
    "    # 4. Residuals histogram\n",
    "    axes[1, 0].hist(standardized_resid, bins=30, edgecolor='black')\n",
    "    axes[1, 0].set_xlabel('Standardized Residuals')\n",
    "    axes[1, 0].set_title('Histogram of Residuals\\n(Check: normality)')\n",
    "    \n",
    "    # 5. Cook's Distance (Influential points)\n",
    "    cooks_d = influence.cooks_distance[0]\n",
    "    axes[1, 1].stem(range(len(cooks_d)), cooks_d, markerfmt=',')\n",
    "    axes[1, 1].axhline(y=4/len(cooks_d), color='r', linestyle='--', \n",
    "                       label=\"Cook's D threshold (4/n)\")\n",
    "    axes[1, 1].set_xlabel('Observation')\n",
    "    axes[1, 1].set_ylabel(\"Cook's Distance\")\n",
    "    axes[1, 1].set_title(\"Cook's Distance\\n(Check: influential points)\")\n",
    "    axes[1, 1].legend()\n",
    "    \n",
    "    # 6. Leverage vs Residuals\n",
    "    leverage = influence.hat_matrix_diag\n",
    "    axes[1, 2].scatter(leverage, studentized_resid, alpha=0.5)\n",
    "    axes[1, 2].axhline(y=0, color='r', linestyle='--')\n",
    "    axes[1, 2].axhline(y=2, color='orange', linestyle='--', alpha=0.5)\n",
    "    axes[1, 2].axhline(y=-2, color='orange', linestyle='--', alpha=0.5)\n",
    "    axes[1, 2].set_xlabel('Leverage')\n",
    "    axes[1, 2].set_ylabel('Studentized Residuals')\n",
    "    axes[1, 2].set_title('Residuals vs Leverage\\n(Check: influential outliers)')\n",
    "    \n",
    "    # 7-9: Residuals vs each predictor (for linearity check)\n",
    "    predictor_cols = X.columns[:3] if len(X.columns) >= 3 else X.columns\n",
    "    for idx, col in enumerate(predictor_cols):\n",
    "        ax = axes[2, idx]\n",
    "        ax.scatter(X[col], residuals, alpha=0.5)\n",
    "        ax.axhline(y=0, color='r', linestyle='--')\n",
    "        ax.set_xlabel(col)\n",
    "        ax.set_ylabel('Residuals')\n",
    "        ax.set_title(f'Residuals vs {col}\\n(Check: linearity)')\n",
    "        # Add lowess\n",
    "        lowess_line = lowess(residuals, X[col], frac=0.3)\n",
    "        ax.plot(lowess_line[:, 0], lowess_line[:, 1], 'g-', linewidth=2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_dir}/diagnostic_plots.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Statistical tests\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STATISTICAL TESTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. Shapiro-Wilk (normality of residuals)\n",
    "    shapiro_stat, shapiro_p = stats.shapiro(residuals)\n",
    "    print(\"\\n1. Shapiro-Wilk Test (Normality of Residuals):\")\n",
    "    print(f\"   Statistic: {shapiro_stat:.4f}, p-value: {shapiro_p:.4f}\")\n",
    "    print(f\"   {'✓ PASS' if shapiro_p > 0.05 else '✗ FAIL'} - Residuals {'are' if shapiro_p > 0.05 else 'are NOT'} normally distributed\")\n",
    "    \n",
    "    # 2. Breusch-Pagan (homoscedasticity)\n",
    "    from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "    bp_stat, bp_p, _, _ = het_breuschpagan(residuals, X)\n",
    "    print(\"\\n2. Breusch-Pagan Test (Homoscedasticity):\")\n",
    "    print(f\"   Statistic: {bp_stat:.4f}, p-value: {bp_p:.4f}\")\n",
    "    print(f\"   {'✓ PASS' if bp_p > 0.05 else '✗ FAIL'} - Variance {'is' if bp_p > 0.05 else 'is NOT'} constant\")\n",
    "    \n",
    "    # 3. Durbin-Watson (independence/autocorrelation)\n",
    "    from statsmodels.stats.stattools import durbin_watson\n",
    "    dw_stat = durbin_watson(residuals)\n",
    "    print(\"\\n3. Durbin-Watson Test (Independence):\")\n",
    "    print(f\"   Statistic: {dw_stat:.4f}\")\n",
    "    print(f\"   {'✓ PASS' if 1.5 < dw_stat < 2.5 else '⚠ WARNING'} - Residuals {'show no' if 1.5 < dw_stat < 2.5 else 'may show'} autocorrelation\")\n",
    "    print(\"   (DW ≈ 2 is ideal; <1 or >3 is problematic)\")\n",
    "    \n",
    "    # 4. VIF (multicollinearity)\n",
    "    print(\"\\n4. Variance Inflation Factor (Multicollinearity):\")\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Variable\"] = X.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    print(vif_data.to_string(index=False))\n",
    "    print(\"   Rule: VIF < 5 is good; 5-10 is moderate; >10 is problematic\")\n",
    "    \n",
    "    # 5. Influential points summary\n",
    "    print(\"\\n5. Influential Points:\")\n",
    "    n_high_cooks = (cooks_d > 4/len(cooks_d)).sum()\n",
    "    print(f\"   Points with high Cook's D (>4/n): {n_high_cooks}\")\n",
    "    if n_high_cooks > 0:\n",
    "        high_cooks_idx = np.where(cooks_d > 4/len(cooks_d))[0]\n",
    "        print(f\"   Indices: {high_cooks_idx[:10]}\")  # Show first 10\n",
    "    \n",
    "    n_high_leverage = (leverage > 2*X.shape[1]/len(leverage)).sum()\n",
    "    print(f\"   Points with high leverage (>2p/n): {n_high_leverage}\")\n",
    "    \n",
    "    # 6. Outliers\n",
    "    n_outliers = (np.abs(studentized_resid) > 3).sum()\n",
    "    print(\"\\n6. Outliers:\")\n",
    "    print(f\"   Points with |studentized residuals| > 3: {n_outliers}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    return influence, cooks_d, leverage\n",
    "\n",
    "\n",
    "def run_comprehensive_dx(model: linear_model.RegressionResultsWrapper, data: pd.DataFrame, save_path):\n",
    "    # Run diagnostics\n",
    "    X = data[model.model.exog_names[1:]]\n",
    "    y = data[model.model.endog_names]\n",
    "    comprehensive_diagnostics(model, X, y, data, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba738c22",
   "metadata": {},
   "source": [
    "## Complete Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7df8e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars = [\n",
    "    \"LV\",\n",
    "    \"CP\",\n",
    "    \"periCSF\",\n",
    "    \"allCSF\",\n",
    "    \"thirdV\",\n",
    "    \"thirdV_width\",\n",
    "    \"THALAMUS_1\",\n",
    "    \"medial\",\n",
    "    \"posterior\",\n",
    "    \"ventral\",\n",
    "    \"anterior\",\n",
    "    \"t2lv\",\n",
    "    \"PRL\", \n",
    "    \"cortical_thickness\",\n",
    "    \"brain\",\n",
    "    \"white\",\n",
    "    \"grey\",\n",
    "]\n",
    "\n",
    "data = df.join(df_thomas)[MS_patients]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da984d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"PHASE 1: VARIABLE SCREENING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "\n",
    "# Screen all variables\n",
    "save_dir = fig_path / \"screening\"\n",
    "transformations_needed = []\n",
    "for var in all_vars:\n",
    "    skew, kurt = screen_variable(data, var, save=True, save_dir=save_dir)\n",
    "    if abs(skew) > 1:\n",
    "        transformations_needed.append(var)\n",
    "        suggest_transformation(data, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12238792",
   "metadata": {},
   "source": [
    "Transform the variables and recheck them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c76d8cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(3.462898310952633), np.float64(16.154759684513582))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prl_transformed = transform_data(data, \"PRL\", transformations=[\"logp1\", \"sqrt\"])\n",
    "for var in [\"logp1\", \"sqrt\"]:\n",
    "    col = f\"PRL_{var}\"\n",
    "    screen_variable(prl_transformed, col, save=True, save_dir=save_dir)\n",
    "\n",
    "screen_variable(prl_transformed, \"PRL\", save=True, save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63080ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PRL_logp1 Transformation Recommendations:\n",
      "Skewness: 1.37\n",
      "→ Right-skewed distribution detected\n",
      "  ⚠ Has zeros - consider:\n",
      "    - log(x + 1)\n",
      "    - sqrt(x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(1.3743278556265233)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggest_transformation(prl_transformed, \"PRL_logp1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a02ca661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([302.,   0.,  66.,   0.,  50.,  30.,   5.,   9.,   3.,   3.]),\n",
       " array([0.        , 0.27080502, 0.54161004, 0.81241506, 1.08322008,\n",
       "        1.3540251 , 1.62483012, 1.89563514, 2.16644016, 2.43724518,\n",
       "        2.7080502 ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.log1p(data['PRL']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d59add15",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for var in all_vars:\n",
    "    formula = f\"{var} ~ age + Female + tiv\"\n",
    "    models[var] = sm.OLS.from_formula(formula, data=data).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8673d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srs-9/.virtualenvs/ms_mri/lib/python3.13/site-packages/statsmodels/nonparametric/smoothers_lowess.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  res, _ = _lowess(y, x, x, np.ones_like(x),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STATISTICAL TESTS\n",
      "============================================================\n",
      "\n",
      "1. Shapiro-Wilk Test (Normality of Residuals):\n",
      "   Statistic: 0.9974, p-value: 0.6864\n",
      "   ✓ PASS - Residuals are normally distributed\n",
      "\n",
      "2. Breusch-Pagan Test (Homoscedasticity):\n",
      "   Statistic: 8.3174, p-value: 0.0399\n",
      "   ✗ FAIL - Variance is NOT constant\n",
      "\n",
      "3. Durbin-Watson Test (Independence):\n",
      "   Statistic: 2.1201\n",
      "   ✓ PASS - Residuals show no autocorrelation\n",
      "   (DW ≈ 2 is ideal; <1 or >3 is problematic)\n",
      "\n",
      "4. Variance Inflation Factor (Multicollinearity):\n",
      "Variable        VIF\n",
      "     age   1.031330\n",
      "  Female   1.423534\n",
      "     tiv   1.395076\n",
      "    cont 258.098274\n",
      "   Rule: VIF < 5 is good; 5-10 is moderate; >10 is problematic\n",
      "\n",
      "5. Influential Points:\n",
      "   Points with high Cook's D (>4/n): 26\n",
      "   Indices: [  6  13  27  53  69  71  83  86 122 154]\n",
      "   Points with high leverage (>2p/n): 24\n",
      "\n",
      "6. Outliers:\n",
      "   Points with |studentized residuals| > 3: 2\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "outcome = \"CP\"\n",
    "model_data = data[~data[outcome].isna()]\n",
    "save_dir = fig_path / outcome\n",
    "if not save_dir.exists():\n",
    "    os.makedirs(save_dir)\n",
    "run_comprehensive_dx(models[outcome], model_data, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55708946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_regression_check(data, outcome_var, predictor_vars, covariates=[]):\n",
    "    \"\"\"\n",
    "    Complete workflow from screening to diagnostics\n",
    "    \"\"\"\n",
    "    import statsmodels.api as sm\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"PHASE 1: VARIABLE SCREENING\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Screen all variables\n",
    "    all_vars = [outcome_var] + predictor_vars + covariates\n",
    "    transformations_needed = {}\n",
    "    \n",
    "    for var in all_vars:\n",
    "        print(f\"\\n--- Screening {var} ---\")\n",
    "        skew, kurt = screen_variable(data, var)\n",
    "        suggest_transformation(data, var)\n",
    "        \n",
    "        if abs(skew) > 1:\n",
    "            print(f\"\\n⚠ {var} may need transformation\")\n",
    "            trans_results = compare_transformations(data, var)\n",
    "            transformations_needed[var] = trans_results\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PHASE 2: MODEL FITTING\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Prepare data (apply chosen transformations here)\n",
    "    X = data[predictor_vars + covariates].copy()\n",
    "    y = data[outcome_var].copy()\n",
    "    \n",
    "    # Add constant\n",
    "    X = sm.add_constant(X)\n",
    "    \n",
    "    # Fit model\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    print(model.summary())\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PHASE 3: DIAGNOSTIC CHECKS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Run diagnostics\n",
    "    influence, cooks_d, leverage = comprehensive_diagnostics(\n",
    "        model, X, y, data\n",
    "    )\n",
    "    \n",
    "    # Decision summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"RECOMMENDATIONS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if transformations_needed:\n",
    "        print(\"\\n⚠ Variables needing attention:\")\n",
    "        for var in transformations_needed:\n",
    "            print(f\"  - {var}\")\n",
    "        print(\"\\nRecommendation: Apply transformations and re-run analysis\")\n",
    "    else:\n",
    "        print(\"\\n✓ All variables look reasonable\")\n",
    "    \n",
    "    return model, influence\n",
    "\n",
    "\n",
    "def model_diagnostics(res: linear_model.RegressionResultsWrapper, data: pd.DataFrame):\n",
    "    # Run diagnostics\n",
    "    X = data[res.model.endog_names]\n",
    "    y = data[res.model.exog_names]\n",
    "    influence, cooks_d, leverage = comprehensive_diagnostics(\n",
    "        res, X, y, data\n",
    "    )\n",
    "    \n",
    "    # Decision summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"RECOMMENDATIONS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if transformations_needed:\n",
    "        print(\"\\n⚠ Variables needing attention:\")\n",
    "        for var in transformations_needed:\n",
    "            print(f\"  - {var}\")\n",
    "        print(\"\\nRecommendation: Apply transformations and re-run analysis\")\n",
    "    else:\n",
    "        print(\"\\n✓ All variables look reasonable\")\n",
    "    \n",
    "    return res, influence\n",
    "# Usage example:\n",
    "# model, influence = complete_regression_check(\n",
    "#     data=df,\n",
    "#     outcome_var='CP',\n",
    "#     predictor_vars=['predictor', 'LV'],\n",
    "#     covariates=['THALAMUS_1', 'age', 'Female', 'tiv']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3424e020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "statsmodels.regression.linear_model.RegressionResultsWrapper"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_count_transformations(data, count_var, outcome, covariates=['age', 'Female', 'tiv']):\n",
    "    \"\"\"\n",
    "    Compare different transformations of a count predictor\n",
    "    \"\"\"\n",
    "    import statsmodels.api as sm\n",
    "    \n",
    "    # Create transformations\n",
    "    data[f'{count_var}_log1p'] = np.log1p(data[count_var])\n",
    "    data[f'{count_var}_sqrt'] = np.sqrt(data[count_var])\n",
    "    \n",
    "    transformations = {\n",
    "        'raw': count_var,\n",
    "        'log(x+1)': f'{count_var}_log1p',\n",
    "        'sqrt': f'{count_var}_sqrt'\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for trans_name, trans_var in transformations.items():\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Testing: {trans_name}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Build model: outcome ~ count_transform + covariates\n",
    "        model_vars = [trans_var] + covariates\n",
    "        df_model = data[[outcome] + model_vars].dropna()\n",
    "        \n",
    "        X = df_model[model_vars].copy()\n",
    "        y = df_model[outcome].copy()\n",
    "        X = sm.add_constant(X)\n",
    "        \n",
    "        # Fit\n",
    "        model = sm.OLS(y, X).fit()\n",
    "        \n",
    "        # Get diagnostics\n",
    "        residuals = model.resid\n",
    "        fitted = model.fittedvalues\n",
    "        \n",
    "        # Key metrics\n",
    "        from scipy import stats\n",
    "        shapiro_stat, shapiro_p = stats.shapiro(residuals)\n",
    "        \n",
    "        from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "        bp_stat, bp_p, _, _ = het_breuschpagan(residuals, X)\n",
    "        \n",
    "        # Distribution of predictor\n",
    "        pred_skew = df_model[trans_var].skew()\n",
    "        \n",
    "        results[trans_name] = {\n",
    "            'model': model,\n",
    "            'predictor_skew': pred_skew,\n",
    "            'residuals_normal_p': shapiro_p,\n",
    "            'homoscedastic_p': bp_p,\n",
    "            'r_squared': model.rsquared,\n",
    "            'aic': model.aic,\n",
    "            'coef': model.params[trans_var],\n",
    "            'p_value': model.pvalues[trans_var]\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nPredictor skewness: {pred_skew:.3f}\")\n",
    "        print(f\"Residuals normal (p): {shapiro_p:.3f}\")\n",
    "        print(f\"Homoscedastic (p): {bp_p:.3f}\")\n",
    "        print(f\"R²: {model.rsquared:.3f}\")\n",
    "        print(f\"AIC: {model.aic:.1f}\")\n",
    "        print(f\"\\nCoefficient for {trans_var}: {model.params[trans_var]:.4f} (p={model.pvalues[trans_var]:.4f})\")\n",
    "    \n",
    "    # Summary comparison\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"COMPARISON SUMMARY\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    comparison_df = pd.DataFrame(results).T\n",
    "    comparison_df = comparison_df[['predictor_skew', 'residuals_normal_p', \n",
    "                                     'homoscedastic_p', 'r_squared', 'aic']]\n",
    "    print(comparison_df.to_string())\n",
    "    \n",
    "    # Recommendation\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"RECOMMENDATION\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Find best by AIC and assumption tests\n",
    "    best_aic = comparison_df['aic'].idxmin()\n",
    "    best_skew = comparison_df['predictor_skew'].abs().idxmin()\n",
    "    \n",
    "    print(f\"Lowest AIC: {best_aic}\")\n",
    "    print(f\"Lowest |skewness|: {best_skew}\")\n",
    "    \n",
    "    return results, comparison_df\n",
    "\n",
    "# Usage:\n",
    "# results, comparison = compare_count_transformations(\n",
    "#     data=df,\n",
    "#     count_var='PRL_count',\n",
    "#     outcome='CP',\n",
    "#     covariates=['age', 'Female', 'tiv']\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms_mri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
